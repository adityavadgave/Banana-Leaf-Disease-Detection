# -*- coding: utf-8 -*-
"""BananaVGG16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FC73KgJODkdHYGro3y_XftMyulSMBYP5
"""

!pip install patool

import patoolib
patoolib.extract_archive("/content/BananaLSD.zip")

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16

img_height, img_width = 224, 224
batch_size = 32

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

train_generator = datagen.flow_from_directory(
    '/content/B/BananaLSD/OriginalSet',
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',  # Classification task
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    '/content/B/BananaLSD/OriginalSet',
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))

for layer in vgg_base.layers:
  layer.trainable = False

def build_classifier(vgg_base, num_classes):
    x = vgg_base.output
    x = layers.Flatten()(x)
    x = layers.Dense(256, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    output = layers.Dense(num_classes, activation='softmax')(x)
    model = models.Model(inputs=vgg_base.input, outputs=output)
    return model

num_classes = len(train_generator.class_indices)
model = build_classifier(vgg_base, num_classes)

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    epochs=10,
    validation_data=validation_generator
)

# %rm -rf /content/U

import numpy as np
from tensorflow.keras.preprocessing import image

def load_and_preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))  # Adjust target size as needed
    img_array = image.img_to_array(img)  # Convert to array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array /= 255.0  # Rescale to [0, 1] if that was done in the generator
    return img_array

# Example image paths
test_image_paths = [
    '/content/B/BananaLSD/AugmentedSet/healthy/0.jpeg', # healthy
    '/content/B/BananaLSD/AugmentedSet/cordana/0.jpeg', # cordana
    '/content/B/BananaLSD/AugmentedSet/pestalotiopsis/1.jpeg', #pestalotiopsis
    '/content/B/BananaLSD/AugmentedSet/sigatoka/0.jpeg', #sigatoka
    # Add more image paths as needed
]

for img_path in test_image_paths:
    img_array = load_and_preprocess_image(img_path)
    predictions = model.predict(img_array)

    # If using categorical crossentropy, use argmax to get the class index
    predicted_class = np.argmax(predictions, axis=1)
    print(f'Predicted class for {img_path}: {predicted_class}')

import matplotlib.pyplot as plt

# Assuming you have a mapping of class indices to class names
class_indices = train_generator.class_indices
class_labels = {v: k for k, v in class_indices.items()}  # Reverse mapping

plt.figure(figsize=(10, 10))
for i, img_path in enumerate(test_image_paths):
    img_array = load_and_preprocess_image(img_path)
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions, axis=1)[0]

    plt.subplot(1, len(test_image_paths), i + 1)
    plt.imshow(image.load_img(img_path))  # Load original image
    plt.title(class_labels[predicted_class])  # Show predicted class label
    plt.axis('off')
plt.tight_layout()
plt.show()

